{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ktbQAC-Xfvku"
      },
      "source": [
        "## Data Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {},
        "colab_type": "code",
        "id": "FQ0GwLD7fkO3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['dataset']\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir(\"../input\"))\n",
        "print(os.listdir(\"../input/dataset/dataset\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rtcL6uLDfkO_"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BtFHREU2fkPA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.12.1\n",
            "0\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hPjrVskrfkPD"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KBoTqWBlfkPE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import MultiStepLR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3y6zGj92fkPG"
      },
      "source": [
        "## Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wDOKqTl6fkPH"
      },
      "outputs": [],
      "source": [
        "dataroot = \"/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/dataset\"\n",
        "ckptroot = \"./\"\n",
        "\n",
        "lr = 1e-4\n",
        "weight_decay = 1e-5\n",
        "batch_size = 32\n",
        "num_workers = 8\n",
        "test_size = 0.8\n",
        "shuffle = True\n",
        "\n",
        "epochs = 80\n",
        "start_epoch = 0\n",
        "resume = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U7E4M2ynfkPJ"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "swFFOrkRfkPK"
      },
      "outputs": [],
      "source": [
        "def toDevice(datas, device):\n",
        "    \"\"\"Enable cuda.\"\"\"\n",
        "    imgs, angles = datas\n",
        "    return imgs.float().to(device), angles.float().to(device)\n",
        "\"\"\n",
        "\n",
        "def augment(dataroot, imgName, angle):\n",
        "    \"\"\"Data augmentation.\"\"\"\n",
        "    name = dataroot + '/IMG/' + imgName.split('\\\\')[-1]\n",
        "    current_image = cv2.imread(name)\n",
        "\n",
        "    if current_image is None:\n",
        "        print(name)\n",
        "\n",
        "    current_image = current_image[65:-25, :, :]\n",
        "    if np.random.rand() < 0.5:\n",
        "        current_image = cv2.flip(current_image, 1)\n",
        "        angle = angle * -1.0\n",
        "\n",
        "    return current_image, angle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yOo86RC1fkPM"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "j0n38m6vfkPN"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "from scipy import signal\n",
        "\n",
        "def load_data(data_dir, test_size):\n",
        "    \"\"\"Load training data and train validation split\"\"\"\n",
        "    # reads CSV file into a single dataframe variable\n",
        "    data_df = pd.read_csv(os.path.join(data_dir, 'driving_log.csv'),\n",
        "                          names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
        "\n",
        "    # smooth data signal with `savgol_filter`\n",
        "    data_df[\"steering\"] = signal.savgol_filter(data_df[\"steering\"].values.tolist(), 51, 11)\n",
        "\n",
        "    # Divide the data into training set and validation set\n",
        "    train_len = int(test_size * data_df.shape[0])\n",
        "    valid_len = data_df.shape[0] - train_len\n",
        "    trainset, valset = data.random_split(\n",
        "        data_df.values.tolist(), lengths=[train_len, valid_len])\n",
        "\n",
        "    return trainset, valset\n",
        "\n",
        "trainset, valset = load_data(dataroot, test_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BzY3zIFdfkPb"
      },
      "source": [
        "## Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-DpSjiP-fkPf"
      },
      "outputs": [],
      "source": [
        "class TripletDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, dataroot, samples, transform=None):\n",
        "        self.samples = samples\n",
        "        self.dataroot = dataroot\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_samples = self.samples[index]\n",
        "        steering_angle = float(batch_samples[3])\n",
        "\n",
        "        center_img, steering_angle_center = augment(self.dataroot, batch_samples[0], steering_angle)\n",
        "        left_img, steering_angle_left     = augment(self.dataroot, batch_samples[1], steering_angle + 0.4)\n",
        "        right_img, steering_angle_right   = augment(self.dataroot, batch_samples[2], steering_angle - 0.4)\n",
        "\n",
        "        center_img = self.transform(center_img)\n",
        "        left_img   = self.transform(left_img)\n",
        "        right_img  = self.transform(right_img)\n",
        "\n",
        "        return (center_img, steering_angle_center), (left_img, steering_angle_left), (right_img, steering_angle_right)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FUfByxjNfkPj"
      },
      "source": [
        "## Get data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GV_h604FfkPk",
        "outputId": "ebdd8196-2093-44ca-a56c-5465f4b816d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Preparing dataset ...\n"
          ]
        }
      ],
      "source": [
        "print(\"==> Preparing dataset ...\")\n",
        "def data_loader(dataroot, trainset, valset, batch_size, shuffle, num_workers):\n",
        "    \"\"\"Self-Driving vehicles simulator dataset Loader.\n",
        "\n",
        "    Args:\n",
        "        trainset: training set\n",
        "        valset: validation set\n",
        "        batch_size: training set input batch size\n",
        "        shuffle: whether shuffle during training process\n",
        "        num_workers: number of workers in DataLoader\n",
        "\n",
        "    Returns:\n",
        "        trainloader (torch.utils.data.DataLoader): DataLoader for training set\n",
        "        testloader (torch.utils.data.DataLoader): DataLoader for validation set\n",
        "    \"\"\"\n",
        "    transformations = transforms.Compose(\n",
        "        [transforms.Lambda(lambda x: (x / 127.5) - 1.0)])\n",
        "\n",
        "    # Load training data and validation data\n",
        "    training_set = TripletDataset(dataroot, trainset, transformations)\n",
        "    trainloader = DataLoader(training_set,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=shuffle,\n",
        "                             num_workers=num_workers)\n",
        "\n",
        "    validation_set = TripletDataset(dataroot, valset, transformations)\n",
        "    valloader = DataLoader(validation_set,\n",
        "                           batch_size=batch_size,\n",
        "                           shuffle=shuffle,\n",
        "                           num_workers=num_workers)\n",
        "\n",
        "    return trainloader, valloader\n",
        "\n",
        "\n",
        "trainloader, validationloader = data_loader(dataroot,\n",
        "                                            trainset, valset,\n",
        "                                            batch_size,\n",
        "                                            shuffle,\n",
        "                                            num_workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dDdWHeMifkPn"
      },
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1K-KmFHWfkPo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Initialize model ...\n",
            "==> Initialize model done ...\n"
          ]
        }
      ],
      "source": [
        "class NetworkNvidia(nn.Module):\n",
        "    \"\"\"NVIDIA model used in the paper.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize NVIDIA model.\n",
        "\n",
        "        NVIDIA model used\n",
        "            Image normalization to avoid saturation and make gradients work better.\n",
        "            Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
        "            Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
        "            Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
        "            Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
        "            Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
        "            Drop out (0.5)\n",
        "            Fully connected: neurons: 100, activation: ELU\n",
        "            Fully connected: neurons: 50, activation: ELU\n",
        "            Fully connected: neurons: 10, activation: ELU\n",
        "            Fully connected: neurons: 1 (output)\n",
        "\n",
        "        the convolution layers are meant to handle feature engineering\n",
        "        the fully connected layer for predicting the steering angle.\n",
        "        \"\"\"\n",
        "        super(NetworkNvidia, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 24, 5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(24, 36, 5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(36, 48, 5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(48, 64, 3),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(64, 64, 3),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.linear_layers = nn.Sequential(\n",
        "            nn.Linear(in_features=64 * 2 * 33, out_features=100),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(in_features=100, out_features=50),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(in_features=50, out_features=10),\n",
        "            nn.Linear(in_features=10, out_features=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        input = input.view(input.size(0), 3, 70, 320)\n",
        "        output = self.conv_layers(input)\n",
        "        # print(output.shape)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.linear_layers(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "# Define model\n",
        "print(\"==> Initialize model ...\")\n",
        "model = NetworkNvidia()\n",
        "print(\"==> Initialize model done ...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HxGAzAzDfkPu"
      },
      "source": [
        "## Define optimizer and criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_iH3OhLBfkPu"
      },
      "outputs": [],
      "source": [
        "# Define optimizer and criterion\n",
        "optimizer = optim.Adam(model.parameters(),lr=1e-4,weight_decay=weight_decay)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pw1poQoYfkPy"
      },
      "source": [
        "## Learning rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "P1MCyJhSfkPz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# learning rate scheduler\n",
        "scheduler = MultiStepLR(optimizer, milestones=[30, 50], gamma=0.1)\n",
        "\n",
        "# transfer to gpu\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OM520SyQfkP1"
      },
      "source": [
        "## Resume training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "luVRBv3CfkP2"
      },
      "outputs": [],
      "source": [
        "if resume:\n",
        "    print(\"==> Loading checkpoint ...\")\n",
        "    checkpoint = torch.load(\"../input/pretrainedmodels/both-nvidia-model-61.h5\",\n",
        "                            map_location=lambda storage, loc: storage)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3f1RloYefkP3"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gC9EK0w0fkP5"
      },
      "outputs": [],
      "source": [
        "class Trainer(object):\n",
        "    \"\"\"Trainer.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 ckptroot,\n",
        "                 model,\n",
        "                 device,\n",
        "                 epochs,\n",
        "                 criterion,\n",
        "                 optimizer,\n",
        "                 scheduler,\n",
        "                 start_epoch,\n",
        "                 trainloader,\n",
        "                 validationloader):\n",
        "        \"\"\"Self-Driving car Trainer.\n",
        "\n",
        "        Args:\n",
        "            model:\n",
        "            device:\n",
        "            epochs:\n",
        "            criterion:\n",
        "            optimizer:\n",
        "            start_epoch:\n",
        "            trainloader:\n",
        "            validationloader:\n",
        "\n",
        "        \"\"\"\n",
        "        super(Trainer, self).__init__()\n",
        "\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.epochs = epochs\n",
        "        self.ckptroot = ckptroot\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.start_epoch = start_epoch\n",
        "        self.trainloader = trainloader\n",
        "        self.validationloader = validationloader\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Training process.\"\"\"\n",
        "        self.model.to(self.device)\n",
        "        for epoch in range(self.start_epoch, self.epochs + self.start_epoch):\n",
        "            self.scheduler.step()\n",
        "            \n",
        "            # Training\n",
        "            train_loss = 0.0\n",
        "            self.model.train()\n",
        "\n",
        "            for local_batch, (centers, lefts, rights) in enumerate(self.trainloader):\n",
        "                # Transfer to GPU\n",
        "                centers, lefts, rights = toDevice(centers, self.device), toDevice(\n",
        "                    lefts, self.device), toDevice(rights, self.device)\n",
        "\n",
        "                # Model computations\n",
        "                self.optimizer.zero_grad()\n",
        "                datas = [centers, lefts, rights]\n",
        "                for data in datas:\n",
        "                    imgs, angles = data\n",
        "                    # print(\"training image: \", imgs.shape)\n",
        "                    outputs = self.model(imgs)\n",
        "                    loss = self.criterion(outputs, angles.unsqueeze(1))\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "\n",
        "                    train_loss += loss.data.item()\n",
        "\n",
        "                if local_batch % 100 == 0:\n",
        "\n",
        "                    print(\"Training Epoch: {} | Loss: {}\".format(epoch, train_loss / (local_batch + 1)))\n",
        "\n",
        "            # Validation\n",
        "            self.model.eval()\n",
        "            valid_loss = 0\n",
        "            with torch.set_grad_enabled(False):\n",
        "                for local_batch, (centers, lefts, rights) in enumerate(self.validationloader):\n",
        "                    # Transfer to GPU\n",
        "                    centers, lefts, rights = toDevice(centers, self.device), toDevice(\n",
        "                        lefts, self.device), toDevice(rights, self.device)\n",
        "\n",
        "                    # Model computations\n",
        "                    self.optimizer.zero_grad()\n",
        "                    datas = [centers, lefts, rights]\n",
        "                    for data in datas:\n",
        "                        imgs, angles = data\n",
        "                        outputs = self.model(imgs)\n",
        "                        loss = self.criterion(outputs, angles.unsqueeze(1))\n",
        "\n",
        "                        valid_loss += loss.data.item()\n",
        "\n",
        "                    if local_batch % 100 == 0:\n",
        "                        print(\"Validation Loss: {}\".format(valid_loss / (local_batch + 1)))\n",
        "\n",
        "            print()\n",
        "            # Save model\n",
        "            if epoch % 5 == 0 or epoch == self.epochs + self.start_epoch - 1:\n",
        "\n",
        "                state = {\n",
        "                    'epoch': epoch + 1,\n",
        "                    'state_dict': self.model.state_dict(),\n",
        "                    'optimizer': self.optimizer.state_dict(),\n",
        "                    'scheduler': self.scheduler.state_dict(),\n",
        "                }\n",
        "\n",
        "                self.save_checkpoint(state)\n",
        "\n",
        "    def save_checkpoint(self, state):\n",
        "        \"\"\"Save checkpoint.\"\"\"\n",
        "        print(\"==> Save checkpoint ...\")\n",
        "        if not os.path.exists(self.ckptroot):\n",
        "            os.makedirs(self.ckptroot)\n",
        "\n",
        "        torch.save(state, self.ckptroot + 'both-nvidia-model-{}.h5'.format(state['epoch']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ycy2rSL3fkP7",
        "outputId": "3f4bf9c9-bfca-4e2e-8810-1c47af381175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Start training ...\n",
            "/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_39_910.jpg/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_30_15_315.jpg/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_02_190.jpg/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_00_590.jpg\n",
            "\n",
            "\n",
            "/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_30_17_132.jpg/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_28_47_925.jpg\n",
            "/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_33_512.jpg/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_30_00_847.jpg\n",
            "/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_50_742.jpg\n",
            "/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_05_970.jpg/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_45_580.jpg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[ WARN:0@619.726] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_02_190.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.726] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_39_910.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.726] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_30_17_132.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.726] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_00_590.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.727] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_30_15_315.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.728] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_28_42_689.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.730] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_28_47_925.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.731] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_50_742.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.731] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_30_00_847.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.732] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_33_512.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.734] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_45_580.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.739] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_25_954.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.739] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_19_849.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.740] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_30_10_371.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.740] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_58_230.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.742] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_04_880.jpg'): can't open/read file: check file path/integrity\n",
            "[ WARN:0@619.757] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_05_970.jpg'): can't open/read file: check file path/integrity\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ftl/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/ftl/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/ftl/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_8311/399383942.py\", line 12, in __getitem__\n    center_img, steering_angle_center = augment(self.dataroot, batch_samples[0], steering_angle)\n  File \"/tmp/ipykernel_8311/3247483096.py\", line 15, in augment\n    current_image = current_image[65:-25, :, :]\nTypeError: 'NoneType' object is not subscriptable\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m==> Start training ...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=1'>2</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(ckptroot,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=2'>3</a>\u001b[0m                   model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=3'>4</a>\u001b[0m                   device,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=9'>10</a>\u001b[0m                   trainloader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=10'>11</a>\u001b[0m                   validationloader)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=11'>12</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
            "\u001b[1;32m/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb Cell 27\u001b[0m in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=47'>48</a>\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=48'>49</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=50'>51</a>\u001b[0m \u001b[39mfor\u001b[39;00m local_batch, (centers, lefts, rights) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainloader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=51'>52</a>\u001b[0m     \u001b[39m# Transfer to GPU\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=52'>53</a>\u001b[0m     centers, lefts, rights \u001b[39m=\u001b[39m toDevice(centers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), toDevice(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=53'>54</a>\u001b[0m         lefts, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), toDevice(rights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=55'>56</a>\u001b[0m     \u001b[39m# Model computations\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1376\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1375\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1376\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1402\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1402\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1403\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 461\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
            "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ftl/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/ftl/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/ftl/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_8311/399383942.py\", line 12, in __getitem__\n    center_img, steering_angle_center = augment(self.dataroot, batch_samples[0], steering_angle)\n  File \"/tmp/ipykernel_8311/3247483096.py\", line 15, in augment\n    current_image = current_image[65:-25, :, :]\nTypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_25_954.jpg\n",
            "/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_19_849.jpg\n",
            "/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_58_230.jpg/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_30_10_371.jpg\n",
            "\n",
            "/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_29_04_880.jpg\n",
            "/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/datasetIMG/center_2022_10_04_01_28_42_689.jpg\n"
          ]
        }
      ],
      "source": [
        "print(\"==> Start training ...\")\n",
        "trainer = Trainer(ckptroot,\n",
        "                  model,\n",
        "                  device,\n",
        "                  epochs,\n",
        "                  criterion,\n",
        "                  optimizer,\n",
        "                  scheduler,\n",
        "                  start_epoch,\n",
        "                  trainloader,\n",
        "                  validationloader)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "e280f017fd83e25f7ad417c7c2b64a1e1d2aeb804266f8bc85e9c0e6b02d52b1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
