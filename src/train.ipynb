{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ktbQAC-Xfvku"
      },
      "source": [
        "## Data Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {},
        "colab_type": "code",
        "id": "FQ0GwLD7fkO3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['dataset']\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir(\"../input\"))\n",
        "print(os.listdir(\"../input/dataset/dataset\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rtcL6uLDfkO_"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BtFHREU2fkPA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.12.1\n",
            "0\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hPjrVskrfkPD"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KBoTqWBlfkPE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import MultiStepLR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3y6zGj92fkPG"
      },
      "source": [
        "## Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wDOKqTl6fkPH"
      },
      "outputs": [],
      "source": [
        "dataroot = \"/home/ftl/Desktop/e2e-learning-self-driving-cars-master/input/dataset/dataset\"\n",
        "ckptroot = \"./\"\n",
        "\n",
        "lr = 1e-4\n",
        "weight_decay = 1e-5\n",
        "batch_size = 32\n",
        "num_workers = 8\n",
        "test_size = 0.8\n",
        "shuffle = True\n",
        "\n",
        "epochs = 80\n",
        "start_epoch = 0\n",
        "resume = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U7E4M2ynfkPJ"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "swFFOrkRfkPK"
      },
      "outputs": [],
      "source": [
        "def toDevice(datas, device):\n",
        "    \"\"\"Enable cuda.\"\"\"\n",
        "    imgs, angles = datas\n",
        "    return imgs.float().to(device), angles.float().to(device)\n",
        "\"\"\n",
        "\n",
        "def augment(dataroot, imgName, angle):\n",
        "    \"\"\"Data augmentation.\"\"\"\n",
        "    name = dataroot + '/IMG/' + imgName.split('\\\\')[-1]\n",
        "    current_image = cv2.imread(name)\n",
        "\n",
        "    if current_image is None:\n",
        "        print(name)\n",
        "\n",
        "    current_image = current_image[65:-25, :, :]\n",
        "    if np.random.rand() < 0.5:\n",
        "        current_image = cv2.flip(current_image, 1)\n",
        "        angle = angle * -1.0\n",
        "\n",
        "    return current_image, angle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yOo86RC1fkPM"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "j0n38m6vfkPN"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "from scipy import signal\n",
        "\n",
        "def load_data(data_dir, test_size):\n",
        "    \"\"\"Load training data and train validation split\"\"\"\n",
        "    # reads CSV file into a single dataframe variable\n",
        "    data_df = pd.read_csv(os.path.join(data_dir, 'driving_log.csv'),\n",
        "                          names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
        "\n",
        "    # smooth data signal with `savgol_filter`\n",
        "    data_df[\"steering\"] = signal.savgol_filter(data_df[\"steering\"].values.tolist(), 51, 11)\n",
        "\n",
        "    # Divide the data into training set and validation set\n",
        "    train_len = int(test_size * data_df.shape[0])\n",
        "    valid_len = data_df.shape[0] - train_len\n",
        "    trainset, valset = data.random_split(\n",
        "        data_df.values.tolist(), lengths=[train_len, valid_len])\n",
        "\n",
        "    return trainset, valset\n",
        "\n",
        "trainset, valset = load_data(dataroot, test_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BzY3zIFdfkPb"
      },
      "source": [
        "## Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-DpSjiP-fkPf"
      },
      "outputs": [],
      "source": [
        "class TripletDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, dataroot, samples, transform=None):\n",
        "        self.samples = samples\n",
        "        self.dataroot = dataroot\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_samples = self.samples[index]\n",
        "        steering_angle = float(batch_samples[3])\n",
        "\n",
        "        center_img, steering_angle_center = augment(self.dataroot, batch_samples[0], steering_angle)\n",
        "        left_img, steering_angle_left     = augment(self.dataroot, batch_samples[1], steering_angle + 0.4)\n",
        "        right_img, steering_angle_right   = augment(self.dataroot, batch_samples[2], steering_angle - 0.4)\n",
        "\n",
        "        center_img = self.transform(center_img)\n",
        "        left_img   = self.transform(left_img)\n",
        "        right_img  = self.transform(right_img)\n",
        "\n",
        "        return (center_img, steering_angle_center), (left_img, steering_angle_left), (right_img, steering_angle_right)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FUfByxjNfkPj"
      },
      "source": [
        "## Get data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GV_h604FfkPk",
        "outputId": "ebdd8196-2093-44ca-a56c-5465f4b816d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Preparing dataset ...\n"
          ]
        }
      ],
      "source": [
        "print(\"==> Preparing dataset ...\")\n",
        "def data_loader(dataroot, trainset, valset, batch_size, shuffle, num_workers):\n",
        "    \"\"\"Self-Driving vehicles simulator dataset Loader.\n",
        "\n",
        "    Args:\n",
        "        trainset: training set\n",
        "        valset: validation set\n",
        "        batch_size: training set input batch size\n",
        "        shuffle: whether shuffle during training process\n",
        "        num_workers: number of workers in DataLoader\n",
        "\n",
        "    Returns:\n",
        "        trainloader (torch.utils.data.DataLoader): DataLoader for training set\n",
        "        testloader (torch.utils.data.DataLoader): DataLoader for validation set\n",
        "    \"\"\"\n",
        "    transformations = transforms.Compose(\n",
        "        [transforms.Lambda(lambda x: (x / 127.5) - 1.0)])\n",
        "\n",
        "    # Load training data and validation data\n",
        "    training_set = TripletDataset(dataroot, trainset, transformations)\n",
        "    trainloader = DataLoader(training_set,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=shuffle,\n",
        "                             num_workers=num_workers)\n",
        "\n",
        "    validation_set = TripletDataset(dataroot, valset, transformations)\n",
        "    valloader = DataLoader(validation_set,\n",
        "                           batch_size=batch_size,\n",
        "                           shuffle=shuffle,\n",
        "                           num_workers=num_workers)\n",
        "\n",
        "    return trainloader, valloader\n",
        "\n",
        "\n",
        "trainloader, validationloader = data_loader(dataroot,\n",
        "                                            trainset, valset,\n",
        "                                            batch_size,\n",
        "                                            shuffle,\n",
        "                                            num_workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dDdWHeMifkPn"
      },
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1K-KmFHWfkPo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Initialize model ...\n",
            "==> Initialize model done ...\n"
          ]
        }
      ],
      "source": [
        "class NetworkNvidia(nn.Module):\n",
        "    \"\"\"NVIDIA model used in the paper.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize NVIDIA model.\n",
        "\n",
        "        NVIDIA model used\n",
        "            Image normalization to avoid saturation and make gradients work better.\n",
        "            Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
        "            Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
        "            Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
        "            Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
        "            Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
        "            Drop out (0.5)\n",
        "            Fully connected: neurons: 100, activation: ELU\n",
        "            Fully connected: neurons: 50, activation: ELU\n",
        "            Fully connected: neurons: 10, activation: ELU\n",
        "            Fully connected: neurons: 1 (output)\n",
        "\n",
        "        the convolution layers are meant to handle feature engineering\n",
        "        the fully connected layer for predicting the steering angle.\n",
        "        \"\"\"\n",
        "        super(NetworkNvidia, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 24, 5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(24, 36, 5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(36, 48, 5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(48, 64, 3),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(64, 64, 3),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.linear_layers = nn.Sequential(\n",
        "            nn.Linear(in_features=64 * 2 * 33, out_features=100),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(in_features=100, out_features=50),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(in_features=50, out_features=10),\n",
        "            nn.Linear(in_features=10, out_features=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        input = input.view(input.size(0), 3, 70, 320)\n",
        "        output = self.conv_layers(input)\n",
        "        # print(output.shape)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.linear_layers(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "# Define model\n",
        "print(\"==> Initialize model ...\")\n",
        "model = NetworkNvidia()\n",
        "print(\"==> Initialize model done ...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HxGAzAzDfkPu"
      },
      "source": [
        "## Define optimizer and criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_iH3OhLBfkPu"
      },
      "outputs": [],
      "source": [
        "# Define optimizer and criterion\n",
        "optimizer = optim.Adam(model.parameters(),lr=1e-4,weight_decay=weight_decay)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pw1poQoYfkPy"
      },
      "source": [
        "## Learning rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "P1MCyJhSfkPz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# learning rate scheduler\n",
        "scheduler = MultiStepLR(optimizer, milestones=[30, 50], gamma=0.1)\n",
        "\n",
        "# transfer to gpu\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OM520SyQfkP1"
      },
      "source": [
        "## Resume training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "luVRBv3CfkP2"
      },
      "outputs": [],
      "source": [
        "if resume:\n",
        "    print(\"==> Loading checkpoint ...\")\n",
        "    checkpoint = torch.load(\"../input/pretrainedmodels/both-nvidia-model-61.h5\",\n",
        "                            map_location=lambda storage, loc: storage)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3f1RloYefkP3"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gC9EK0w0fkP5"
      },
      "outputs": [],
      "source": [
        "class Trainer(object):\n",
        "    \"\"\"Trainer.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 ckptroot,\n",
        "                 model,\n",
        "                 device,\n",
        "                 epochs,\n",
        "                 criterion,\n",
        "                 optimizer,\n",
        "                 scheduler,\n",
        "                 start_epoch,\n",
        "                 trainloader,\n",
        "                 validationloader):\n",
        "        \"\"\"Self-Driving car Trainer.\n",
        "\n",
        "        Args:\n",
        "            model:\n",
        "            device:\n",
        "            epochs:\n",
        "            criterion:\n",
        "            optimizer:\n",
        "            start_epoch:\n",
        "            trainloader:\n",
        "            validationloader:\n",
        "\n",
        "        \"\"\"\n",
        "        super(Trainer, self).__init__()\n",
        "\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.epochs = epochs\n",
        "        self.ckptroot = ckptroot\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.start_epoch = start_epoch\n",
        "        self.trainloader = trainloader\n",
        "        self.validationloader = validationloader\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Training process.\"\"\"\n",
        "        self.model.to(self.device)\n",
        "        for epoch in range(self.start_epoch, self.epochs + self.start_epoch):\n",
        "            self.scheduler.step()\n",
        "            \n",
        "            # Training\n",
        "            train_loss = 0.0\n",
        "            self.model.train()\n",
        "\n",
        "            for local_batch, (centers, lefts, rights) in enumerate(self.trainloader):\n",
        "                # Transfer to GPU\n",
        "                centers, lefts, rights = toDevice(centers, self.device), toDevice(\n",
        "                    lefts, self.device), toDevice(rights, self.device)\n",
        "\n",
        "                # Model computations\n",
        "                self.optimizer.zero_grad()\n",
        "                datas = [centers, lefts, rights]\n",
        "                for data in datas:\n",
        "                    imgs, angles = data\n",
        "                    # print(\"training image: \", imgs.shape)\n",
        "                    outputs = self.model(imgs)\n",
        "                    loss = self.criterion(outputs, angles.unsqueeze(1))\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "\n",
        "                    train_loss += loss.data.item()\n",
        "\n",
        "                if local_batch % 100 == 0:\n",
        "\n",
        "                    print(\"Training Epoch: {} | Loss: {}\".format(epoch, train_loss / (local_batch + 1)))\n",
        "\n",
        "            # Validation\n",
        "            self.model.eval()\n",
        "            valid_loss = 0\n",
        "            with torch.set_grad_enabled(False):\n",
        "                for local_batch, (centers, lefts, rights) in enumerate(self.validationloader):\n",
        "                    # Transfer to GPU\n",
        "                    centers, lefts, rights = toDevice(centers, self.device), toDevice(\n",
        "                        lefts, self.device), toDevice(rights, self.device)\n",
        "\n",
        "                    # Model computations\n",
        "                    self.optimizer.zero_grad()\n",
        "                    datas = [centers, lefts, rights]\n",
        "                    for data in datas:\n",
        "                        imgs, angles = data\n",
        "                        outputs = self.model(imgs)\n",
        "                        loss = self.criterion(outputs, angles.unsqueeze(1))\n",
        "\n",
        "                        valid_loss += loss.data.item()\n",
        "\n",
        "                    if local_batch % 100 == 0:\n",
        "                        print(\"Validation Loss: {}\".format(valid_loss / (local_batch + 1)))\n",
        "\n",
        "            print()\n",
        "            # Save model\n",
        "            if epoch % 5 == 0 or epoch == self.epochs + self.start_epoch - 1:\n",
        "\n",
        "                state = {\n",
        "                    'epoch': epoch + 1,\n",
        "                    'state_dict': self.model.state_dict(),\n",
        "                    'optimizer': self.optimizer.state_dict(),\n",
        "                    'scheduler': self.scheduler.state_dict(),\n",
        "                }\n",
        "\n",
        "                self.save_checkpoint(state)\n",
        "\n",
        "    def save_checkpoint(self, state):\n",
        "        \"\"\"Save checkpoint.\"\"\"\n",
        "        print(\"==> Save checkpoint ...\")\n",
        "        if not os.path.exists(self.ckptroot):\n",
        "            os.makedirs(self.ckptroot)\n",
        "\n",
        "        torch.save(state, self.ckptroot + 'both-nvidia-model-{}.h5'.format(state['epoch']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ycy2rSL3fkP7",
        "outputId": "3f4bf9c9-bfca-4e2e-8810-1c47af381175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Start training ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ftl/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Epoch: 0 | Loss: 0.48489098995923996\n",
            "Validation Loss: 0.2743423916399479\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 1 | Loss: 0.23226132988929749\n",
            "Validation Loss: 0.20516151562333107\n",
            "\n",
            "Training Epoch: 2 | Loss: 0.24018987640738487\n",
            "Validation Loss: 0.16415536031126976\n",
            "\n",
            "Training Epoch: 3 | Loss: 0.13723944500088692\n",
            "Validation Loss: 0.15018066205084324\n",
            "\n",
            "Training Epoch: 4 | Loss: 0.12702427990734577\n",
            "Validation Loss: 0.07941838726401329\n",
            "\n",
            "Training Epoch: 5 | Loss: 0.12859550304710865\n",
            "Validation Loss: 0.12265307828783989\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 6 | Loss: 0.08376568648964167\n",
            "Validation Loss: 0.11484258063137531\n",
            "\n",
            "Training Epoch: 7 | Loss: 0.16798536106944084\n",
            "Validation Loss: 0.11150114797055721\n",
            "\n",
            "Training Epoch: 8 | Loss: 0.11328765004873276\n",
            "Validation Loss: 0.1057976121082902\n",
            "\n",
            "Training Epoch: 9 | Loss: 0.1281844936311245\n",
            "Validation Loss: 0.12512783706188202\n",
            "\n",
            "Training Epoch: 10 | Loss: 0.09233868308365345\n",
            "Validation Loss: 0.06473446078598499\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 11 | Loss: 0.11277777142822742\n",
            "Validation Loss: 0.1303531415760517\n",
            "\n",
            "Training Epoch: 12 | Loss: 0.10647153481841087\n",
            "Validation Loss: 0.13257161155343056\n",
            "\n",
            "Training Epoch: 13 | Loss: 0.13477646186947823\n",
            "Validation Loss: 0.07798734772950411\n",
            "\n",
            "Training Epoch: 14 | Loss: 0.12432905100286007\n",
            "Validation Loss: 0.11855514161288738\n",
            "\n",
            "Training Epoch: 15 | Loss: 0.07729408610612154\n",
            "Validation Loss: 0.09792784042656422\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 16 | Loss: 0.11493200063705444\n",
            "Validation Loss: 0.0984730813652277\n",
            "\n",
            "Training Epoch: 17 | Loss: 0.08429246209561825\n",
            "Validation Loss: 0.11628637090325356\n",
            "\n",
            "Training Epoch: 18 | Loss: 0.10439769737422466\n",
            "Validation Loss: 0.11048184148967266\n",
            "\n",
            "Training Epoch: 19 | Loss: 0.07475289329886436\n",
            "Validation Loss: 0.07578539289534092\n",
            "\n",
            "Training Epoch: 20 | Loss: 0.10015258751809597\n",
            "Validation Loss: 0.09166447073221207\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 21 | Loss: 0.08026294782757759\n",
            "Validation Loss: 0.0894758366048336\n",
            "\n",
            "Training Epoch: 22 | Loss: 0.08028735965490341\n",
            "Validation Loss: 0.08352713659405708\n",
            "\n",
            "Training Epoch: 23 | Loss: 0.08247815258800983\n",
            "Validation Loss: 0.07558800373226404\n",
            "\n",
            "Training Epoch: 24 | Loss: 0.08675718307495117\n",
            "Validation Loss: 0.06942163221538067\n",
            "\n",
            "Training Epoch: 25 | Loss: 0.05791428964585066\n",
            "Validation Loss: 0.05638560187071562\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 26 | Loss: 0.06446164008229971\n",
            "Validation Loss: 0.09727747831493616\n",
            "\n",
            "Training Epoch: 27 | Loss: 0.045434712432324886\n",
            "Validation Loss: 0.09844407439231873\n",
            "\n",
            "Training Epoch: 28 | Loss: 0.07990133762359619\n",
            "Validation Loss: 0.07789392955601215\n",
            "\n",
            "Training Epoch: 29 | Loss: 0.06734145060181618\n",
            "Validation Loss: 0.06310658436268568\n",
            "\n",
            "Training Epoch: 30 | Loss: 0.03453915286809206\n",
            "Validation Loss: 0.10316814295947552\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 31 | Loss: 0.036522677168250084\n",
            "Validation Loss: 0.07584137376397848\n",
            "\n",
            "Training Epoch: 32 | Loss: 0.07842321041971445\n",
            "Validation Loss: 0.0614251084625721\n",
            "\n",
            "Training Epoch: 33 | Loss: 0.08735204488039017\n",
            "Validation Loss: 0.07101015374064445\n",
            "\n",
            "Training Epoch: 34 | Loss: 0.07422663643956184\n",
            "Validation Loss: 0.07833536341786385\n",
            "\n",
            "Training Epoch: 35 | Loss: 0.03956597251817584\n",
            "Validation Loss: 0.05247965082526207\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 36 | Loss: 0.06966494582593441\n",
            "Validation Loss: 0.06985350884497166\n",
            "\n",
            "Training Epoch: 37 | Loss: 0.055675994604825974\n",
            "Validation Loss: 0.07190251350402832\n",
            "\n",
            "Training Epoch: 38 | Loss: 0.0617912570014596\n",
            "Validation Loss: 0.05850687902420759\n",
            "\n",
            "Training Epoch: 39 | Loss: 0.04424163233488798\n",
            "Validation Loss: 0.061918849125504494\n",
            "\n",
            "Training Epoch: 40 | Loss: 0.04443192854523659\n",
            "Validation Loss: 0.04901641234755516\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 41 | Loss: 0.05830049514770508\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m==> Start training ...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=1'>2</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(ckptroot,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=2'>3</a>\u001b[0m                   model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=3'>4</a>\u001b[0m                   device,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=9'>10</a>\u001b[0m                   trainloader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=10'>11</a>\u001b[0m                   validationloader)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=11'>12</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
            "\u001b[1;32m/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb Cell 27\u001b[0m in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=59'>60</a>\u001b[0m imgs, angles \u001b[39m=\u001b[39m data\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=60'>61</a>\u001b[0m \u001b[39m# print(\"training image: \", imgs.shape)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=61'>62</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(imgs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=62'>63</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(outputs, angles\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=63'>64</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32m/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb Cell 27\u001b[0m in \u001b[0;36mNetworkNvidia.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=45'>46</a>\u001b[0m \u001b[39m\"\"\"Forward pass.\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=46'>47</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mview(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m3\u001b[39m, \u001b[39m70\u001b[39m, \u001b[39m320\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=47'>48</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_layers(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=48'>49</a>\u001b[0m \u001b[39m# print(output.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ftl/Desktop/e2e-learning-self-driving-cars-master/src/train.ipynb#ch0000026?line=49'>50</a>\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mview(output\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(\"==> Start training ...\")\n",
        "trainer = Trainer(ckptroot,\n",
        "                  model,\n",
        "                  device,\n",
        "                  epochs,\n",
        "                  criterion,\n",
        "                  optimizer,\n",
        "                  scheduler,\n",
        "                  start_epoch,\n",
        "                  trainloader,\n",
        "                  validationloader)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "e280f017fd83e25f7ad417c7c2b64a1e1d2aeb804266f8bc85e9c0e6b02d52b1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
